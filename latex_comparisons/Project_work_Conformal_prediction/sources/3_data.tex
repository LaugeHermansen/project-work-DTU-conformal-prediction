A real problem setting is investigated to evaluate how CP is affected by different factors such as which type of model is used for the predictions. As any model can be extended with CP, the problem setting and the model will be sculptured from a previous paper; \textit{"Active Machine Learning and Agency - Bayesian Optimization on EMNIST"}. 

In this paper the EMNIST data set is used, which contains images of grey scaled hand written numbers and letters in a $28 \times 28$ resolution. The data set distinguishes cases of the same letter which yields $62$ different classes. The training set contains $697,932$ data point split equally among the $62$ classes, but only $279,173$ ($40\%$) stratified data points are used for the training of the model. The test set contains $116,323$ data point, but only batches of $500$ are used as calibration sets.  

Below the six random data points are drawn to get an idea of how the data set looks. 

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{Images/letters_clipped.png}
    \caption{Six hand written letters and numbers.}
    \label{fig:cnn_architecture}
\end{figure}

In this project the data set is only used to evaluate CP and the contents of the data set is therefore not important. However, when deploying CP one must evaluate the data set. An example is given with this data set. The EMNIST data set is written by 500 different writers and was collected in 1995. This might create some kind of bias only letters from these 500 people were sampled. An even more important potential bias is that there could be a cultural difference between the 500 authors and the group this letter/number recognizer is supposed to classify. 

Although CP upholds coverage this will not mean that the biases in the dataset will be eradicated. If the data set contains some sort of inherent bias the conformal predictor will too. However, if the calibration set does not, our conformal predictor wonâ€™t either. This is important in real world settings where the model might be trained on a biased data set (only US citerzins with a specific pencil write the letters), but is then applied to the data it is going to be used for. While the model is in use, a calibration set can slowly be gathered from the data that does not include a bias and the conformal predictor model can be deployed without a the bias! This does not mean that the model will somehow learn and erase this bias from its previous learning, but instead that the confidence sets will become larger and uphold coverage. 